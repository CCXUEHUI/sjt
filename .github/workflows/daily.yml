name: Daily Image Crawler

on:
  schedule:
    - cron: '0 16 * * *'  # æ¯å¤©ä¸­å›½æ—¶é—´ 24 ç‚¹ï¼ˆUTC+8ï¼‰
  workflow_dispatch:

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install requests-html pillow flask lxml[html_clean]

      - name: Run crawler and filter
        working-directory: ./py
        run: |
          echo "ğŸš€ å¼€å§‹æ‰§è¡Œ crawler.py"
          python crawler.py
          echo "ğŸ§¹ æ‰§è¡Œ filter.py æ¸…ç†ç«–å›¾"
          python filter.py
          echo "ğŸ“‚ å½“å‰ images æ–‡ä»¶å¤¹å†…å®¹ï¼š"
          ls ../images
          echo "ğŸ“„ å½“å‰ files.txt å†…å®¹ï¼š"
          cat ../images/files.txt || echo "âš ï¸ files.txt ä¸å­˜åœ¨"
