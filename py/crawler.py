import os
import requests
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

BASE_URL = "https://m.tuiimg.com/meinv"
IMG_DIR = "images"
TXT_PATH = os.path.join(IMG_DIR, "files.txt")

# æ¨¡æ‹Ÿ Android + Via æµè§ˆå™¨ UA
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Linux; Android 10; Pixel 3 XL Build/QQ3A.200805.001; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/88.0.4324.93 Mobile Safari/537.36 Via/4.3.9"
}

# åˆ›å»º images æ–‡ä»¶å¤¹
os.makedirs(IMG_DIR, exist_ok=True)

# è¯»å–å·²ä¿å­˜çš„åœ°å€ï¼Œé¿å…é‡å¤ä¸‹è½½
existing_urls = set()
if os.path.exists(TXT_PATH):
    with open(TXT_PATH, "r", encoding="utf-8") as f:
        existing_urls = set(line.strip() for line in f if line.strip())

def is_landscape(img: Image.Image) -> bool:
    return img.width > img.height

def save_image(url: str):
    if url in existing_urls:
        print(f"ğŸ” å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š{url}")
        return
    try:
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½å›¾ç‰‡ï¼š{url}")
        resp = requests.get(url, headers=HEADERS, timeout=10)
        resp.raise_for_status()
        img = Image.open(BytesIO(resp.content))
        print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸ï¼š{img.width}x{img.height}")
        if is_landscape(img):
            filename = os.path.basename(url)
            path = os.path.join(IMG_DIR, filename)
            img.save(path)
            with open(TXT_PATH, "a", encoding="utf-8") as f:
                f.write(url + "\n")
            print(f"âœ… å·²ä¿å­˜æ¨ªå›¾ï¼š{filename}")
        else:
            print(f"â›” è·³è¿‡ç«–å›¾ï¼š{url}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{url}ï¼Œé”™è¯¯ï¼š{e}")

def get_subpages():
    try:
        print(f"ğŸŒ æ­£åœ¨è®¿é—®ä¸»é¡µé¢ï¼š{BASE_URL}")
        resp = requests.get(BASE_URL, headers=HEADERS, timeout=10)
        print(f"ğŸ“„ é¡µé¢çŠ¶æ€ç ï¼š{resp.status_code}")
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        main_div = soup.find("div", class_="main")
        if not main_div:
            print("âš ï¸ é¡µé¢ä¸­æœªæ‰¾åˆ° class='main' çš„ div")
            return []
        links = main_div.find_all("a", href=True)
        subpages = [f"https://m.tuiimg.com{a['href']}" for a in links if a["href"].startswith("/meinv/")]
        print(f"ğŸ”— è·å–åˆ° {
